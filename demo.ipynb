{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding = utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cbamResNet import *\n",
    "from loader.data_loader import *\n",
    "from tools.other_tools import *\n",
    "from tools.augment_tools import *\n",
    "from tools.data_tools import *\n",
    "from tools.evaluate_tools import *\n",
    "from tools.model_tools import *\n",
    "from tools.other_tools import *\n",
    "from config import config\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "transform =  { \"train\":transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(0.5),\n",
    "                transforms.RandomVerticalFlip(0.1),\n",
    "                transforms.RandomApply([transforms.RandomRotation(30)], p=0.3),\n",
    "                transforms.RandomApply([transforms.ColorJitter(brightness=0.5,contrast=0.8)], p=0.5),\n",
    "                transforms.RandomApply([transforms.ColorJitter(hue=0.2)], p=0.1),\n",
    "                transforms.RandomApply([transforms.CenterCrop(config.size*0.6)], p=0.4),\n",
    "                transforms.Resize((config.img_height,config.img_width)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "              \"val\":transforms.Compose([\n",
    "                transforms.Resize((config.img_height,config.img_width)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "                \"test\" :transforms.Compose([\n",
    "                transforms.Resize((config.img_height,config.img_width)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "            ])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(config.gpu if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything(config.seed)\n",
    "\n",
    "exists_or_mkdir(config.weights)\n",
    "exists_or_mkdir(config.submit)\n",
    "exists_or_mkdir(config.best_models)\n",
    "exists_or_mkdir(config.logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train dataset\n",
      "get csv file done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142119/142119 [00:00<00:00, 224661.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train and val file...\n",
      "number of train dataset 113696\n",
      "number of validate dataset： 28423\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label = get_csv_files(config.train_data,\"train\")\n",
    "train_labels = np.ones((len(train_label),config.num_classes))*config.negtive_score\n",
    "for i in tqdm(range(len(train_label))):\n",
    "    train_labels[i][train_label[i]] = config.positive_score\n",
    "train_data,train_label,val_data,val_label = split_rand(train_data,train_labels)\n",
    "train_dataset = CCDataset(file=train_data,transform=transform[\"train\"],label=train_label)\n",
    "val_dataset = CCDataset(file=val_data,transform=transform[\"val\"],label=val_label)\n",
    "print(\"number of train dataset\",len(train_dataset))\n",
    "print(\"number of validate dataset：\",len(val_dataset))\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=config.batch_size,shuffle=True,num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=config.batch_size * 2,shuffle=True,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dataset,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cbam_resnet_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = config.lr, momentum=0.5)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_warmup_step = lambda epoch: epoch if epoch <= config.warmup_peak_epoch else config.warmup_peak_epoch*(0.95 ** epoch)\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "scheduler = LambdaLR(optimizer,lr_lambda=lambda_warmup_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_lr(LambdaLR(optimizer,lr_lambda=lambda_warmup_step),config.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "old_eval_acc = 0.1\n",
    "old_eval_loss = 0.05\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch,config.epochs):\n",
    "    '''\n",
    "    eval_loss = evaluate_loss(val_dataloader,model,Loss(),criterion)\n",
    "    if eval_loss<old_eval_loss:\n",
    "        torch.save(model.state_dict(), config.weights+config.model_name+\".pkl\")\n",
    "        print(\"model saved\")\n",
    "        old_eval_loss = eval_loss\n",
    "    '''\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    prbar = tqdm(total=len(train_dataloader))\n",
    "    prbar.set_description(\"training epoch\"+str(epoch))\n",
    "    for iter,(input,target) in enumerate(train_dataloader):\n",
    "        input = Variable(input).to(device)\n",
    "        target = Variable(torch.from_numpy(np.array(target))).to(device)\n",
    "        output = model(input)\n",
    "        loss = criterion(output,target)\n",
    "        if config.fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        '''    \n",
    "        if iter%config.display_interval==0:\n",
    "            print(\"loss:{} {}/{}\".format(loss.cpu().detach().numpy(),iter,epoch))\n",
    "        '''\n",
    "        #backward\n",
    "        if iter%config.step == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        prbar.update(1)\n",
    "        prbar.set_postfix(loss=loss.cpu().detach().numpy())\n",
    "    prbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
